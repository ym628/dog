# 机械狗
<span style="font-size:24px;">   本机器狗创新应用深度集成昇腾全栈 AI 技术生态，以昇思 MindSpore 全场景 AI 框架为核心底座，依托 MindYolo 套件在昇思大模型平台实现高效模型训练，搭配昇腾技术路线的香橙派 AIPro 开发板与 MindSpore Lite 轻量化推理引擎，构建起 "训推一体" 的闭环方案。全栈工具链协同发力，为机器狗智能应用落地提供坚实技术支撑。</span>
![机械狗展示.jpeg](https://raw.gitcode.com/user-images/assets/8737315/b02a50ac-6c3a-44f0-b588-e79dd4102292/629860afcbde72fddd888af7fc62dd4a.jpeg '629860afcbde72fddd888af7fc62dd4a.jpeg')
##  代码结构
本项目涉及机械狗控制底层代码，简单运动和复杂运动代码，各类工具以及多个推理模型，工程目录如下图所示：
```
 dog
  ├── control #机械狗烧录代码
  ├── demo #香橙派运行机械狗
  ├── train #追踪模型训练
  └── README.md #描述文件
```

## 介绍
### 硬件结构

机械狗运动部分是由以下部分组成：

1. 四个具有2自由度的机械腿以及中间的主体部分实现的，机械腿的曲柄连杆结构保证了机械狗可以单独操作每一条腿的运动，每条腿上的两个关节由两个行星轮减速电机驱动，并放置在中间的主体部分。
2. 下位机由带有串口扩展板的两个STM32单片机开发板构成，分为主控F405和从控F103，位于机械狗身体内部。
3. 使用补充的3D连接固定件固定摄像头云台。
4. 摄像头云台连接一块ESP32下位机控制摄像头的移动，再通过USB扩展坞将所有的线连接到香橙派开发板。

**图1** 机械狗外观结构图
<img width="4096" height="2838" alt="image" src="https://github.com/user-attachments/assets/1f04ccd1-63d1-4e27-a014-c8a0fd8ba370" />



### 软件结构
本机械狗软件采用**分层解耦式架构设计**，深度融合昇腾全栈AI技术生态，构建起从“硬件驱动到应用落地”的完整技术链路，实现“训推一体、软硬协同”的智能闭环，具体分层及细节如下：

### 1. CANN层（异构计算中间层）
- 核心组件：CANN（昇腾异构计算架构）
- 核心功能：作为硬件层与AI框架层的核心桥梁，完成硬件资源抽象、异构算子适配、算力调度优化与底层驱动封装，屏蔽硬件差异，为上层AI框架提供统一、高效的算力调用接口，保障AI模型在昇腾硬件上的高性能运行。

### 2. AI框架层（训推一体核心层）
- 核心组件：MindSpore（全场景深度学习框架）
- 核心功能：
  1.  训练侧：基于MindSpore YOLO套件快速完成人体跟踪模型、手势识别模型、YOLO目标检测模型的构建、训练与优化，支持大规模数据并行训练与模型精度调优；
  2.  部署侧：提供统一的模型开发、训练、导出与部署接口，实现“云端训练-端侧部署”的无缝衔接，构建完整的“训推一体”技术闭环；
  3.  兼容性：支持全场景设备适配，兼顾云端训练的大规模算力需求与端侧部署的轻量化需求。

### 3. 模型层（智能算法支撑层）
- 核心模型：
  1.  基础检测模型：YOLO系列目标检测模型，实现人体、手势等目标的快速定位与初步识别，为上层业务提供基础检测数据；
  2.  业务赋能模型：人体跟踪模型（实现目标持续锁定与轨迹预测）、手势识别模型（实现交互指令解析与场景切换触发），基于基础检测结果完成精细化业务推理；
- 核心功能：承载机械狗核心AI智能能力，将视觉感知数据转化为可落地的业务推理结果，为应用层提供标准化算法输出，支撑跟踪、交互、决策等上层业务场景。

### 4. 端侧推理层（轻量化部署层）
- 核心组件：MindSpore Lite（轻量化深度学习推理引擎）
- 核心功能：将云端训练完成的AI模型进行轻量化转换、优化与部署，适配香橙派AIPro等边缘硬件的资源约束，实现低延迟、低功耗、高性能的端侧实时推理，保障视觉感知、指令解析等任务的实时响应，满足机械狗动态控制的业务需求。

### 5. 应用层（业务功能落地层）
- 核心功能模块：
  1.  视频采集与流处理模块：基于摄像头云台实现实时画面拉流、帧数据预处理与共享内存分发，为推理任务提供高质量视觉输入；
  2.  人体锁定追踪模块：融合人体检测结果与卡尔曼滤波算法，实现目标持续锁定、轨迹预测与多目标场景下的精准跟踪，支持锁定/解锁状态智能切换；
  3.  手势交互识别模块：基于手势识别模型解析控制指令，实现机械狗运动启停、场景切换、跟踪目标更换等交互操作；
  4.  运动控制与指令下发模块：接收推理结果，生成标准化运动控制指令，通过串口与下位机（STM32/ESP32）通信，实现机械狗四足运动、摄像头云台调节等硬件执行动作；

- 核心功能：封装上层业务逻辑，整合各底层能力，对外提供可直接使用的智能业务接口，实现机械狗视觉追踪、手势交互、自主运动等核心应用场景的落地。




**图2** 机械狗软件结构图
![机械狗软件结构图.png](https://raw.gitcode.com/user-images/assets/8737315/ea39c973-4b2c-40d8-b949-0a18707bd188/a9b18138f4fbe636031b1af239728233.png 'a9b18138f4fbe636031b1af239728233.png')
### 功能与原理介绍

**图1** 功能原理图
![img](https://www.hiascend.com/doc_center/source/zh/Atlas200IDKA2DeveloperKit/23.0.RC2/Application%20Cases/mdadg/figure/zh-cn_image_0000001663635202.png)

机械狗分为上位机即香橙派开发者套件，下位机即STM32和ESP32单片机，通过命令行以及手势语音等方式输入到机械狗上的各类传感器以及上位机上，在场景切换后进入到主函数，初始化各类硬件底层设备完成之后，就可以进入到各个场景对应的模块中进行信息拉取和推理进程了。以摄像头的为例，利用摄像头拉流到视频信息之后，输入到场景循环函数中，经过CV模型得到推理结果，再将后处理的结果回传到场景循环模块中，针对控制模块做动作下发，传递到STM32下位机上控制四足的运动，即可完成一个简单的流程。

### 控制与运动部分

机械狗的运动控制部分的实现原理图如图1所示：

**图1** 机械狗运动控制原理图
![img](https://www.hiascend.com/doc_center/source/zh/Atlas200IDKA2DeveloperKit/23.0.RC2/Application%20Cases/mdadg/figure/zh-cn_image_0000001663795214.png)

在上位机（开发者套件）上部署离线推理模型后，在上位机上根据推理结果生成对应的运动控制指令。指令下发到STM32单片机上，由串口中断函数来进行串口数据传输的接收。在上位机端和STM32使用相同的校验码的生成和校验方式，如果串口处接收到是上位机发出的指令，则会进入到对应的中断函数中进行运动状态的改变和操作。

在下位机（STM32）的初始化过程中：

1. 会开启多个任务序列，包括初始化电机零点位置、陀螺仪初始化、显示屏显示、LED灯显示、蜂鸣器初始化及串口发送数据初始化中断函数标记归位等操作。
2. 主进程在完整这些操作之后，进入获取控制端以及四足行动的部分，在收取到上位机发出的指令后，下位机进行解析，获取机器狗的姿态全局变量参数以及运动的两个方向的线速度和角速度。
3. 进入到机械狗的运动解析部分进行运算，解析接下来的运动需中每一个机械腿的运动位置，以及八个电机需要转到的目标位置，并下发指令到从控的STM32上，通过串口下发到电机处。其中的电机使用PID来编码，在整个姿态变化和运动的过程中，通过PID控制电机的目标位置和实际运动位置误差以及自我纠正误差。
4. 同时，为了防止运动过程中机械狗摔倒，加入了陀螺仪的运算，且可以在显示屏上显示实际数据。MPU6050陀螺仪会计算平衡环的数值大小用来修正不同方向上的非水平位置变化，然后加入到机械腿的运动控制中。得到了控制机械腿的目标位置后，可以通过机械腿路径规划算法实现实时计算机械腿机械腿的运动位置，使机械狗能够稳步前进以及完成其他动作。

**图2** 运动控制时序图1
![img](https://www.hiascend.com/doc_center/source/zh/Atlas200IDKA2DeveloperKit/23.0.RC2/Application%20Cases/mdadg/figure/zh-cn_image_0000001711731005.png)

**图3** 运动控制时序图2
![img](https://www.hiascend.com/doc_center/source/zh/Atlas200IDKA2DeveloperKit/23.0.RC2/Application%20Cases/mdadg/figure/zh-cn_image_0000001663811150.png)

### 锁定追踪部分

机械狗的锁定追踪部分的时序图如图1、图2和图3所示：

**图1** 机械狗锁定追踪时序图1
![img](https://www.hiascend.com/doc_center/source/zh/Atlas200IDKA2DeveloperKit/23.0.RC2/Application%20Cases/mdadg/figure/zh-cn_image_0000001716066033.png)

**图2** 机械狗锁定追踪时序图2
![img](https://www.hiascend.com/doc_center/source/zh/Atlas200IDKA2DeveloperKit/23.0.RC2/Application%20Cases/mdadg/figure/zh-cn_image_0000001668106754.png)

**图3** 机械狗锁定追踪时序图3

![img](https://www.hiascend.com/doc_center/source/zh/Atlas200IDKA2DeveloperKit/23.0.RC2/Application%20Cases/mdadg/figure/zh-cn_image_0000001716147201.png)

1. 在启动主程序后，首先进行摄像头和共享内存的初始化，拉流后在运动控制器端初始化，获取STM32和ESP32的端口信息。
2. 其中，外设的连接端口号ttyUSB*中具体的号码是由拔插的先后顺序决定的，所以需要提前查询端口信息并返回到主程序中。而后在追踪任务的进程中初始化，再开启两个手势识别和人体检测的模型进程，分别进行初始化，然后在控制端下位机设置舵机的角度，调整到方便机械狗追踪的角度，将识别锁定追踪目标的状态初始化为解锁，锁定计数归零。
3. 在拉流分发的进程中开启循环获取frame并放入共享内存中，然后再启动循环并开始并行的手势识别和人体识别的推理进程。此处使用两个消息队列来防止手势识别和人体识别出现异帧不同步的情况，将两个过程同步之后返回两个bboxes，分别是手势和人体的识别框存储数据，再利用如下公式来判断锁定的目标框：
   1. 在出现比值大于0.9的帧时，计数器值加1，在连续五帧都超过这个比值后，将锁定目标的FLAG置为True，然后设置舵机的信息，进行目标的锁定追踪；若在已经锁定目标的状态下就需要锁定到该框并且使用卡尔曼滤波的方式进行目标框的匹配，进而推算出要追随的目标，即使在有多人存在的场景仍然可以准确追踪到目标。
   2. 在超过20帧没有识别到目标之后以及出现解锁的手势超过5帧之后就会将机械狗的下位机中的运动FLAG设定为停止，然后上位机上的解锁标志回归为解锁，并且下发动作，然后等待下一个锁定的手势出现，继续追踪新的目标。
## 组装
### 准备组装
机械狗所需配件如表1所示：

当前样例仅在Ubuntu OS适配验证过，未在openEuler OS适配验证，推荐烧录镜像时，烧录Ubuntu OS镜像。

表1 机械狗配件表

|名称  |  数量/个| 规格 |
|--|--|--|
| 开发者套件及电源适配器 | 1 | 唯一 |
|机械狗裸机 | 1 | 裸机 |
|摄像头两轴云台|1|	两轴云台精简版|
|广角摄像头模组  | 1 | 118°广角无畸变模组 |
|ESP32机器人开发板|1|	主板+Type-C数据线|
|移动电源  | 1 |  |
|单头六角铜柱|40|M2.5*7+6|
| 单头六角铜柱 | 40 | M4*7+6 |
|防松螺母|40|	M4|
| 防松螺母 | 40 | 	M2.5 |
|圆头螺母|40|M4*5|
|圆头螺母  | 40 | M2.5*5 |
|[3D打印支撑板](https://ascend-repo.obs.cn-east-2.myhuaweicloud.com/Atlas%20200I%20DK%20A2/DevKit/samples/23.0.RC2/e2e-samples/RobotDog/%E6%9C%BA%E6%A2%B0%E7%8B%97%E9%A2%9D%E5%A4%96%E7%BB%93%E6%9E%84.zip)（下载文件后通过3D打印）|6|唯一规格|
| USB扩展坞 | 1 | 单USB转4口USB3.0 |
|Micro USB数据传输线|1|一定要有数据传输功能，不可仅为充电线|
| USB Wifi模块 | 1 | - |


### 组装步骤
首先将机械狗裸机平放在地面上，然后将3D打印好的支撑板用单头六角铜柱和防松螺母固定在机械狗的裸机上平面上，具体的位置如图1所示：

图1 安装固定
<img width="2838" height="4096" alt="image" src="https://github.com/user-attachments/assets/878e7f08-680f-42b6-9253-8d963a876bf9" />                                                                         
从上到下依次为摄像头承载板、开发板承载板以及电池仓，按照图中的螺丝与单头螺柱位置固定即可。

将电源放入到电池仓中，使用电池挡板固定，如图2所示：

图2 安装电源
![image.png](https://raw.gitcode.com/user-images/assets/8737315/a35c575a-015b-4e86-b44a-1cef10de1a0a/image.png 'image.png')
将开发者套件从底板上拆下并固定到3D打印出来的开发板承载板上，如图3 固定开发板所示：    
图3 固定开发板
![image.png](https://raw.gitcode.com/user-images/assets/8737315/4d733c51-c019-46f3-a45c-bcedf7cf5798/image.png 'image.png')
将两轴云台上原有的普通摄像头拆下，替换上无畸变的广角摄像头模组，再将云台安装到摄像头承载板上，如图4 所示：

图4 安装广角摄像头模组
![image.png](https://raw.gitcode.com/user-images/assets/8737315/fdd5499a-08fb-48ef-a991-90f2be50d9a2/image.png 'image.png')

其中上半部分的舵机连接到ESP32上的26号接口，棕色线接地靠近5V一侧，下半部分的舵机连接到ESP32上的25号接口，棕色线接地靠近5V一侧。
总体的接线方式如图5所示：

图5 接线图
![image.png](https://raw.gitcode.com/user-images/assets/8737315/a921c25c-dc5a-4d84-ab0d-19afbed115fc/image.png 'image.png')

将各个电源线连接好后，需要使用一根Micro USB数据线连接到机械狗内部的主控F405一侧的MicroUSB端口，另一端连接到插到开发板上的USB扩展坞上，再将USBWifi模块插到开发板的USB接口上，将USB摄像头和ESP32接到USB扩展坞上，即可完成接线。                          
图6 接线图
![image.png](https://raw.gitcode.com/user-images/assets/8737315/3b56f92d-4d6b-42c1-92bc-e39a8a9685d2/image.png 'image.png')


