# 机械狗

##  代码结构
本项目涉及机械狗控制底层代码，简单运动和复杂运动代码，各类工具以及多个推理模型，工程目录如下图所示：
```
dog
  ├── control #机械狗烧录代码
  ├── demo #香橙派运行机械狗
  ├── train #追踪模型训练
  └── README.md #
```

## 介绍
### 外观结构

机械狗运动部分是由以下部分组成：

1. 四个具有2自由度的机械腿以及中间的主体部分实现的，机械腿的曲柄连杆结构保证了机械狗可以单独操作每一条腿的运动，每条腿上的两个关节由两个行星轮减速电机驱动，并放置在中间的主体部分。
2. 下位机由带有串口扩展板的两个STM32单片机开发板构成，分为主控F405和从控F103，位于机械狗身体内部。
3. 使用补充的3D连接固定件固定摄像头云台、开发板以及开发板电源
4. 摄像头云台连接一块ESP32下位机控制摄像头的移动，再通过USB扩展坞将所有的线连接到开发板上，再使用Wifi模块连接到开发板上。

**图1** 机械狗外观结构图
![img](https://www.hiascend.com/doc_center/source/zh/Atlas200IDKA2DeveloperKit/23.0.RC2/Application%20Cases/mdadg/figure/zh-cn_image_0000001650180870.png)

### 功能与原理介绍

**图1** 功能原理图
![img](https://www.hiascend.com/doc_center/source/zh/Atlas200IDKA2DeveloperKit/23.0.RC2/Application%20Cases/mdadg/figure/zh-cn_image_0000001663635202.png)

机械狗分为上位机即香橙派开发者套件，下位机即STM32和ESP32单片机，通过命令行以及手势语音等方式输入到机械狗上的各类传感器以及上位机上，在场景切换后进入到主函数，初始化各类硬件底层设备完成之后，就可以进入到各个场景对应的模块中进行信息拉取和推理进程了。以摄像头的为例，利用摄像头拉流到视频信息之后，输入到场景循环函数中，经过CV模型得到推理结果，再将后处理的结果回传到场景循环模块中，针对控制模块做动作下发，传递到STM32下位机上控制四足的运动，即可完成一个简单的流程。

### 控制与运动部分

机械狗的运动控制部分的实现原理图如图1所示：

**图1** 机械狗运动控制原理图
![img](https://www.hiascend.com/doc_center/source/zh/Atlas200IDKA2DeveloperKit/23.0.RC2/Application%20Cases/mdadg/figure/zh-cn_image_0000001663795214.png)

在上位机（开发者套件）上部署离线推理模型后，在上位机上根据推理结果生成对应的运动控制指令。指令下发到STM32单片机上，由串口中断函数来进行串口数据传输的接收。在上位机端和STM32使用相同的校验码的生成和校验方式，如果串口处接收到是上位机发出的指令，则会进入到对应的中断函数中进行运动状态的改变和操作。

在下位机（STM32）的初始化过程中：

1. 会开启多个任务序列，包括初始化电机零点位置、陀螺仪初始化、显示屏显示、LED灯显示、蜂鸣器初始化及串口发送数据初始化中断函数标记归位等操作。
2. 主进程在完整这些操作之后，进入获取控制端以及四足行动的部分，在收取到上位机发出的指令后，下位机进行解析，获取机器狗的姿态全局变量参数以及运动的两个方向的线速度和角速度。
3. 进入到机械狗的运动解析部分进行运算，解析接下来的运动需中每一个机械腿的运动位置，以及八个电机需要转到的目标位置，并下发指令到从控的STM32上，通过串口下发到电机处。其中的电机使用PID来编码，在整个姿态变化和运动的过程中，通过PID控制电机的目标位置和实际运动位置误差以及自我纠正误差。
4. 同时，为了防止运动过程中机械狗摔倒，加入了陀螺仪的运算，且可以在显示屏上显示实际数据。MPU6050陀螺仪会计算平衡环的数值大小用来修正不同方向上的非水平位置变化，然后加入到机械腿的运动控制中。得到了控制机械腿的目标位置后，可以通过机械腿路径规划算法实现实时计算机械腿机械腿的运动位置，使机械狗能够稳步前进以及完成其他动作。

**图2** 运动控制时序图1
![img](https://www.hiascend.com/doc_center/source/zh/Atlas200IDKA2DeveloperKit/23.0.RC2/Application%20Cases/mdadg/figure/zh-cn_image_0000001711731005.png)

**图3** 运动控制时序图2
![img](https://www.hiascend.com/doc_center/source/zh/Atlas200IDKA2DeveloperKit/23.0.RC2/Application%20Cases/mdadg/figure/zh-cn_image_0000001663811150.png)

### 锁定追踪部分

机械狗的锁定追踪部分的时序图如图1、图2和图3所示：

**图1** 机械狗锁定追踪时序图1
![img](https://www.hiascend.com/doc_center/source/zh/Atlas200IDKA2DeveloperKit/23.0.RC2/Application%20Cases/mdadg/figure/zh-cn_image_0000001716066033.png)

**图2** 机械狗锁定追踪时序图2
![img](https://www.hiascend.com/doc_center/source/zh/Atlas200IDKA2DeveloperKit/23.0.RC2/Application%20Cases/mdadg/figure/zh-cn_image_0000001668106754.png)

**图3** 机械狗锁定追踪时序图3
![img](https://www.hiascend.com/doc_center/source/zh/Atlas200IDKA2DeveloperKit/23.0.RC2/Application%20Cases/mdadg/figure/zh-cn_image_0000001716147201.png)

1. 在启动主程序后，首先进行摄像头和共享内存的初始化，拉流后在运动控制器端初始化，获取STM32和ESP32的端口信息。
2. 其中，外设的连接端口号ttyUSB*中具体的号码是由拔插的先后顺序决定的，所以需要提前查询端口信息并返回到主程序中。而后在追踪任务的进程中初始化，再开启两个手势识别和人体检测的模型进程，分别进行初始化，然后在控制端下位机设置舵机的角度，调整到方便机械狗追踪的角度，将识别锁定追踪目标的状态初始化为解锁，锁定计数归零。
3. 在拉流分发的进程中开启循环获取frame并放入共享内存中，然后再启动循环并开始并行的手势识别和人体识别的推理进程。此处使用两个消息队列来防止手势识别和人体识别出现异帧不同步的情况，将两个过程同步之后返回两个bboxes，分别是手势和人体的识别框存储数据，再利用如下公式来判断锁定的目标框：
   1. 在出现比值大于0.9的帧时，计数器值加1，在连续五帧都超过这个比值后，将锁定目标的FLAG置为True，然后设置舵机的信息，进行目标的锁定追踪；若在已经锁定目标的状态下就需要锁定到该框并且使用卡尔曼滤波的方式进行目标框的匹配，进而推算出要追随的目标，即使在有多人存在的场景仍然可以准确追踪到目标。
   2. 在超过20帧没有识别到目标之后以及出现解锁的手势超过5帧之后就会将机械狗的下位机中的运动FLAG设定为停止，然后上位机上的解锁标志回归为解锁，并且下发动作，然后等待下一个锁定的手势出现，继续追踪新的目标。

